{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def normalize_data(x):\n",
    "    x_n = x.copy()  # Create a copy to avoid modifying the original data\n",
    "    mean_values = np.mean(x_n, axis=0)\n",
    "    std_values = np.std(x_n, axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    std_values[std_values == 0] = 1\n",
    "    \n",
    "    x_n -= mean_values\n",
    "    x_n /= std_values\n",
    "\n",
    "\n",
    "    return (x_n , mean_values, std_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cancer_data = pd.read_csv(\"cancer_data.csv\", header=None)\n",
    "# Set the indices for both rows and columns\n",
    "cancer_data.index = range(len(cancer_data))\n",
    "cancer_data.columns = range(len(cancer_data.columns))\n",
    "cancer_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cancer_data_normalized, mean_values, std_values  = normalize_data(cancer_data)\n",
    "cancer_data_normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "expected = cancer_data_normalized.values[:, -1] # extract the y column  \n",
    "cancer_data_normalized = cancer_data_normalized.values[:, :-1] # remove y column from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cancer_data_normalized_for_svd = cancer_data_normalized.copy() # save a copy from the original normalize data, will be used later\n",
    "cancer_data_normalized = np.insert(cancer_data_normalized, 0, 1, axis=1)  # add intercept column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $h_{\\Theta}(x^{(i)})$ is the predicted value of the $i^{th}$ observation using the hypothesis function $h_{\\Theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def prediction (x, params): # H-teta(x)\n",
    "     return np.dot(x, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cost of a guess -- squared errors\n",
    "$$\n",
    "J(\\Theta) = \\frac{1}{2m} \\sum_{i=1}^{n} (h_{\\Theta}(x^{(i)}) - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "You saw this in the classroom. In this notation:\n",
    "\n",
    "* $m$ is the number of observations\n",
    "* $n$ is the number of the attributes for each observation \n",
    "* $x^{(i)}$ is the feature vector of the $i^{th}$ observation\n",
    "* $y^{(i)}$ is the actual value of the $i^{th}$ observation\n",
    "* $h_{\\Theta}(x^{(i)})$ is the predicted value of the $i^{th}$ observation using the hypothesis function $h_{\\Theta}$\n",
    "* $\\Theta$ are the parameters of the model\n",
    "\n",
    "we divide by 2m to make the math easier when we take the derivative of the cost function. It doesn't change the shape of the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def params_cost (X, y, params): #j(teta)\n",
    "    prediction_vector = X @ params\n",
    "    cost = ((y - prediction_vector) ** 2.0).sum()\n",
    "    return (1.0 / (2 * len(X))) * cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the gradient as a dependence on $\\Theta$\n",
    "$$\n",
    "{\\nabla}J(\\Theta) = \\frac{1}{\\text(m)} \\cdot (X^T \\cdot (X \\cdot \\text(\\Theta) - y))\n",
    "$$\n",
    "\n",
    "* $m$ is the number of rows in X matrix\n",
    "* $x^{(i)}$ is the feature vector of the $i^{th}$ observation\n",
    "* $y^{(i)}$ is the actual value of the $i^{th}$ observation\n",
    "* $\\Theta$ are the parameters of the model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def gradient_calculation(X, y, params): #J-grad (teta)\n",
    "    return 1/len(X) * (X.T @ (X @ params - y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def gradient_descent(X, y, a):\n",
    "    params = np.zeros(X.shape[1]) # set initial guess for the parametrs\n",
    "    costs = []\n",
    "    cost = params_cost(X, y, params)\n",
    "    costs.append(cost)\n",
    "    for _ in range(1000):\n",
    "        grad = gradient_calculation(X, y, params)\n",
    "        params = params - a * grad # change the parameters, in depandence of gradient and learning rate\n",
    "        cost = params_cost(X, y, params)\n",
    "        costs.append(cost)\n",
    "        # add stopping condition, if we stable over the cost \n",
    "        if( np.abs((costs[-1] - costs[-2])) < 10e-8 ):\n",
    "            break\n",
    "\n",
    "    return (costs, params)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the model parameters using vanilla algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "run_times = []\n",
    "costs = [] \n",
    "a = 0.1 # set first learning rate\n",
    "for _ in range(4):\n",
    "    start_time = time.time()\n",
    "    res = gradient_descent(cancer_data_normalized, expected, a)\n",
    "    end_time = time.time()\n",
    "    run_times.append(end_time - start_time)\n",
    "    costs.append(res[0])\n",
    "    a /= 10\n",
    "\n",
    "x_axis = max(len(costs[0]) , len(costs[1]),len(costs[2]),len(costs[3]))\n",
    "\n",
    "# Plotting convergence curves for different 'a' values against the number of iterations\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, a in enumerate([0.1, 0.01, 0.001, 0.0001]):\n",
    "    plt.plot(range(len(costs[i])), costs[i],label=f'a = {a},cost = {np.round(costs[i][-1], 4)}, iterations = {len(costs[i])-1}, run-time = {np.round(run_times[i], 3)}')\n",
    "\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost function')\n",
    "plt.title('Convergence of Gradient Descent for Different Learning Rates')\n",
    "plt.legend(title='Running arguments')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the Impact of Learning Rate on Cost Convergence in Gradient Descent: Insights from Vanilla SGD Algorithm\n",
    "In our analysis, we observe that the vanilla gradient descent (SGD) algorithm yields favorable cost outcomes. However, it's evident that the choice of learning rate significantly influences the convergence behavior.\n",
    "\n",
    "For larger alpha values, we witness substantial fluctuations in the cost function, indicating significant jumps. Conversely, smaller alpha values result in more stable cost function shapes, albeit requiring a higher number of iterations to achieve satisfactory cost values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def shuffle_data(X):\n",
    "    # Make a copy of the input data\n",
    "    x_copy = X.copy()\n",
    "    shuffled_df = x_copy.sample(frac=1, random_state=42)  # frac=1 means shuffle all rows\n",
    "    shuffled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return shuffled_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the model parameters using mini-batch algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def batch_gradient_descent(X, y, a=0.1, batch_size=32):\n",
    "    k = len(X) // batch_size\n",
    "    if (len(X) % batch_size != 0):\n",
    "        k += 1\n",
    "\n",
    "    params = np.zeros(X.shape[1])\n",
    "    costs = []\n",
    "    costs.append(params_cost(X, y, params))\n",
    "\n",
    "    current_index = 0  # Initialize the current index to keep track of where we are in the dataset\n",
    "\n",
    "    for _ in range(1000):\n",
    "        start_idx = current_index\n",
    "        end_idx = (current_index + batch_size) % len(X)  # Compute the end index for the batch\n",
    "\n",
    "        if end_idx < start_idx:\n",
    "            indices = np.concatenate((np.arange(start_idx, len(X)), np.arange(0, end_idx)))\n",
    "        else:\n",
    "            indices = np.arange(start_idx, end_idx)\n",
    "\n",
    "        x_i = X[indices]\n",
    "        y_i = y[indices]\n",
    "\n",
    "        params_0 = gradient_calculation(x_i, y_i ,params)\n",
    "        params = params - a * params_0\n",
    "        cost = params_cost(X, y, params)\n",
    "        costs.append(cost)\n",
    "\n",
    "        current_index = end_idx  # Update the current index for the next iteration\n",
    "\n",
    "    return (costs, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use of mini-batch algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = shuffle_data(cancer_data)  \n",
    "X, mean, std = normalize_data(X)  # Assuming normalize_data returns X, mean, std\n",
    "y = X[:, -1]  # Accessing last column by index\n",
    "X = X[:, :-1]   # Exclude the last column   \n",
    "X = np.insert(X, 0, 1, axis=1)  # Insert column of 1s\n",
    "a = 0.1\n",
    "for _ in range(3):\n",
    "    costs = []\n",
    "    params = []\n",
    "    run_times = []\n",
    "    for i, b in enumerate([16, 32, 64, 128]):\n",
    "        start_time = time.time()\n",
    "        res = batch_gradient_descent(X, y, a, b) \n",
    "        end_time = time.time()\n",
    "        costs.append(res[0])\n",
    "        params.append(res[1])\n",
    "        run_times.append(end_time - start_time)\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, b in enumerate([16, 32, 64, 128]):\n",
    "        iterations = range(len(costs[i]))\n",
    "        plt.plot(iterations, costs[i], label=f'b = {b} cost = { np.round(costs[i][-1], 4)} run-time = {np.round(run_times[i], 4)}')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Cost function')\n",
    "    plt.title(f'Alpha = {a}')\n",
    "    plt.legend(title='batch size')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    a /= 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Mini-Batch Gradient Descent Algorithm\n",
    "Upon transitioning to the mini-batch gradient descent algorithm, notable shifts emerge, particularly in runtime metrics, while maintaining comparable cost outcomes to the vanilla approach.\n",
    "\n",
    "The pivotal change lies in the computation of gradients, where the use of mini-batches introduces smaller multiplicative factors. Consequently, this alteration directly impacts runtime dynamics.\n",
    "\n",
    "Furthermore, the interaction between batch size and learning rate becomes apparent. For smaller batches paired with larger learning rates, we observe less stable cost function shapes, with fluctuations being more pronounced. Conversely, larger batches with smaller learning rates yield smoother cost function trajectories.\n",
    "\n",
    "With a bigger dataset, the impact of this algorithm becomes more pronounced, especially in the time required for tuning. It's noteworthy that while larger batch sizes may offer smoother cost function trajectories, they come at the expense of increased runtime.\n",
    "\n",
    "In summary, leveraging the mini-batch algorithm presents an opportunity for runtime reduction. However, optimizing performance necessitates a delicate balance between batch size and learning rate, as both factors exhibit interdependence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimenstion reduction of the given data using SVD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def svd(X, dim=3):\n",
    "    U, s, _ = np.linalg.svd(X, full_matrices=False)\n",
    "    U_dim = U[:, :dim]\n",
    "    s_dim = s[:dim]  # Create a diagonal matrix from s[:dim]\n",
    "    \n",
    "    X_dim = U_dim @ np.diag(s_dim)\n",
    "\n",
    "    X_dim = np.insert(X_dim, 0, 1, axis=1)\n",
    "\n",
    "    return X_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the model parameters using SGD algorithm with the reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cancer_data_svd = svd(cancer_data_normalized_for_svd, 3)\n",
    "\n",
    "costs = []\n",
    "run_times = []\n",
    "a = 0.1\n",
    "for _ in range(4):\n",
    "    start_time = time.time()\n",
    "    res = gradient_descent(cancer_data_svd, expected, a)\n",
    "    end_time = time.time()\n",
    "    run_times.append(end_time - start_time)\n",
    "    costs.append(res[0])\n",
    "    a /= 10\n",
    "\n",
    "# Define the number of iterations (assuming each convergence curve has the same number of iterations)\n",
    "# num_iterations = len(costs[0])\n",
    "x_axis = max(len(costs[0]) , len(costs[1]),len(costs[2]),len(costs[3]))\n",
    "\n",
    "\n",
    "# Plotting convergence curves for different 'a' values against the number of iterations\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, a in enumerate([ 0.1, 0.01, 0.001 ,0.0001]):\n",
    "   plt.plot(range(len(costs[i])), costs[i],\n",
    "             label=f'a = {a}, cost = {np.round(costs[i][-1], 4)}, iterations = {len(costs[i])-1}, run-time = {np.round(run_times[i], 3)}')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost function')\n",
    "plt.title('Convergence of Gradient Descent for Different Learning Rates using svd')\n",
    "plt.legend(title='Running arguments')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Efficiency through Reduced Data with SVD Algorithm\n",
    "Employing a reduced matrix derived from the singular value decomposition (SVD) algorithm yields remarkable reductions in runtime, despite marginal improvements in the cost function compared to the vanilla approach. This efficiency gain stems from the inherent data compression achieved through SVD.\n",
    "\n",
    "Notably, utilizing the reduced data accelerates the convergence of the cost function, surpassing the speed observed in other algorithms. This rapid convergence significantly contributes to shorter runtimes.\n",
    "\n",
    "Moreover, the inherent advantages of operating on smaller matrices further amplify the runtime benefits. Regardless of the algorithm used, the multiplication of reduced matrices inherently results in expedited computational processes.\n",
    "\n",
    "In summary, the SVD algorithm offers a compelling avenue for efficiency gains, driven by data compression and accelerated convergence rates. These factors collectively lead to notable reductions in runtime, underscoring the algorithm's potential for practical applications.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use of mini-batch algorithm with the reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "a = 0.1\n",
    "for _ in range(3):\n",
    "    costs = []\n",
    "    params = []\n",
    "    run_times = []\n",
    "    for i, b in enumerate([16, 32, 64, 128]):\n",
    "        start_time = time.time()\n",
    "        res = batch_gradient_descent(cancer_data_svd, expected, a, b) \n",
    "        end_time = time.time()\n",
    "        costs.append(res[0])\n",
    "        params.append(res[1])\n",
    "        run_times.append(end_time - start_time)\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, b in enumerate([16, 32, 64, 128]):\n",
    "        iterations = range(len(costs[i]))\n",
    "        plt.plot(iterations, costs[i], label=f'b = {b} cost = { np.round(costs[i][-1], 4)} run-time = {np.round(run_times[i], 4)}')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Cost function')\n",
    "    plt.title(f'Alpha = {a}')\n",
    "    plt.legend(title='batch size')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    a /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving Model Parameters Using Direct SVD Equation Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def params_using_svd(X,y):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    U, s, V = np.linalg.svd(X, full_matrices=False)\n",
    "   \n",
    "    theta = V.T @  (np.diag(1/s)) @ U.T @ y \n",
    "    end_time = time.time()\n",
    "\n",
    "    cost = params_cost(X,y,theta)\n",
    "    \n",
    "\n",
    "    return ( np.round(cost,4),np.round((end_time - start_time),4) )\n",
    "\n",
    "print(params_using_svd(cancer_data_normalized_for_svd,expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def actual_pred(prediction):\n",
    "    y_std = std_values.to_numpy()[-1]\n",
    "    y_mean = mean_values.to_numpy()[-1]\n",
    "    return (prediction * y_std) + y_mean\n",
    "\n",
    "cancer_data_svd = svd(cancer_data_normalized_for_svd)\n",
    "params = gradient_descent(cancer_data_svd, expected, 0.01)[1]\n",
    "h_t = prediction(cancer_data_svd, params)\n",
    "\n",
    "predictions = actual_pred(h_t)\n",
    "actual = actual_pred(expected)\n",
    "\n",
    "indices = range(len(predictions))\n",
    "\n",
    "plt.scatter(indices, predictions - actual, marker='o', color='blue')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted difference')\n",
    "plt.title('Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Noam Huna/AppData/Local/Microsoft/WindowsApps/python3.12.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = shuffle_data(cancer_data)  \n",
    "X = normalize_data(X)[0]  \n",
    "y = X[:, -1]  # Accessing last column by column name\n",
    "X = X[:, :-1]  # Exclude the last column   \n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "params = batch_gradient_descent(X, y, 0.01)[1]\n",
    "\n",
    "h_t = prediction(cancer_data_normalized, params)\n",
    "\n",
    "predictions = actual_pred(h_t)\n",
    "actual = actual_pred(expected)\n",
    "\n",
    "indices = range(len(predictions))\n",
    "\n",
    "plt.scatter(indices, predictions - actual, marker='o', color='blue')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted difference')\n",
    "plt.title('Predictions')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
